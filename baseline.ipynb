{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63360, 1500, 35694, 1500, 53387, 1500)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    D = []\n",
    "    with open(filename) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            label = None\n",
    "            items = l.strip().split('\\t')\n",
    "            if len(items) == 3:\n",
    "                idx, text, label = items\n",
    "#                 label = int(label)\n",
    "            else:\n",
    "                idx, text = items\n",
    "            D.append((idx, text, label))\n",
    "    return D\n",
    "\n",
    "def load_ocnli_data(filename):\n",
    "    D = []\n",
    "    with  open(filename) as f:\n",
    "        for l in f:\n",
    "            label = None\n",
    "            items = l.strip().split('\\t')\n",
    "            if len(items) == 4:\n",
    "                idx, s1, s2, label = items\n",
    "            else:\n",
    "                idx, s1, s2 = items\n",
    "            D.append((idx, s1, s2, label))\n",
    "    return D\n",
    "\n",
    "\n",
    "tnews_train = load_data('/home/mingming.xu/datasets/NLP/ptms_data/TNEWS_train1128.csv')\n",
    "tnews_test = load_data('/home/mingming.xu/datasets/NLP/ptms_data/TNEWS_a.csv')\n",
    "\n",
    "ocemotion_train = load_data('/home/mingming.xu/datasets/NLP/ptms_data/OCEMOTION_train1128.csv')\n",
    "ocemotion_test = load_data('/home/mingming.xu/datasets/NLP/ptms_data/OCEMOTION_a.csv')\n",
    "\n",
    "ocnli_train = load_ocnli_data('/home/mingming.xu/datasets/NLP/ptms_data/OCNLI_train1128.csv')\n",
    "ocnli_test = load_ocnli_data('/home/mingming.xu/datasets/NLP/ptms_data/OCNLI_a.csv')\n",
    "\n",
    "len(tnews_train), len(tnews_test), len(ocemotion_train), len(ocemotion_test), len(ocnli_train), len(ocnli_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('0', '上课时学生手机响个不停,老师一怒之下把手机摔了,家长拿发票让老师赔,大家怎么看待这种事?', '108'),\n",
       " ('0',\n",
       "  \"'你知道多伦多附近有什么吗?哈哈有破布耶...真的书上写的你听哦...你家那块破布是世界上最大的破布,哈哈,骗你的啦它是说尼加拉瓜瀑布是世界上最大的瀑布啦...哈哈哈''爸爸,她的头发耶!我们大扫除椅子都要翻上来我看到木头缝里有头发...一定是xx以前夹到的,你说是不是?[生病]\",\n",
       "  'sadness'),\n",
       " ('0', '一月份跟二月份肯定有一个月份有.', '肯定有一个月份有', '0'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnews_train[0], ocemotion_train[0], ocnli_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precess_label(train_data):\n",
    "    labels = set([d[-1] for d in train_data])\n",
    "    label2id = {k:v for v, k in enumerate(labels)}\n",
    "    id2label = {v:k for k, v in label2id.items()}\n",
    "    return labels, label2id, id2label\n",
    "\n",
    "tnews_labels, tnews_label2id, tnews_id2label = precess_label(tnews_train)\n",
    "ocnli_labels, ocnli_label2id, ocnli_id2label = precess_label(ocnli_train)\n",
    "ocemotion_labels, ocemotion_label2id, ocemotion_id2label = precess_label(ocemotion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'100',\n",
       "  '101',\n",
       "  '102',\n",
       "  '103',\n",
       "  '104',\n",
       "  '106',\n",
       "  '107',\n",
       "  '108',\n",
       "  '109',\n",
       "  '110',\n",
       "  '112',\n",
       "  '113',\n",
       "  '114',\n",
       "  '115',\n",
       "  '116'},\n",
       " {'0', '1', '2'},\n",
       " {'anger', 'disgust', 'fear', 'happiness', 'like', 'sadness', 'surprise'})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnews_labels, ocnli_labels, ocemotion_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('0', '上课时学生手机响个不停,老师一怒之下把手机摔了,家长拿发票让老师赔,大家怎么看待这种事?', 10),\n",
       " ('0', '一月份跟二月份肯定有一个月份有.', '肯定有一个月份有', 2),\n",
       " ('0',\n",
       "  \"'你知道多伦多附近有什么吗?哈哈有破布耶...真的书上写的你听哦...你家那块破布是世界上最大的破布,哈哈,骗你的啦它是说尼加拉瓜瀑布是世界上最大的瀑布啦...哈哈哈''爸爸,她的头发耶!我们大扫除椅子都要翻上来我看到木头缝里有头发...一定是xx以前夹到的,你说是不是?[生病]\",\n",
       "  6))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnews_train = [d[:-1] + (tnews_label2id[d[-1]],) for d in tnews_train]\n",
    "ocnli_train = [d[:-1] + (ocnli_label2id[d[-1]],) for d in ocnli_train]\n",
    "ocemotion_train = [d[:-1] + (ocemotion_label2id[d[-1]],) for d in ocemotion_train]\n",
    "\n",
    "tnews_train[0], ocnli_train[0], ocemotion_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit4nlp.models import *\n",
    "from toolkit4nlp.layers import *\n",
    "from toolkit4nlp.utils import *\n",
    "from toolkit4nlp.optimizers import *\n",
    "from toolkit4nlp.tokenizers import *\n",
    "from toolkit4nlp.backend import *\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert config\n",
    "\n",
    "config_path = '/home/mingming.xu/pretrain/NLP/nezha_base_wwm/bert_config.json'\n",
    "checkpoint_path = '/home/mingming.xu/pretrain/NLP/nezha_base_wwm/model.ckpt'\n",
    "dict_path = '/home/mingming.xu/pretrain/NLP/nezha_base_wwm/vocab.txt'\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "batch_size=16\n",
    "maxlen=256\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class batch_data_generator(DataGenerator):\n",
    "    def __init__(self, label_mask, **kwargs):\n",
    "        super(batch_data_generator, self).__init__(**kwargs)\n",
    "        self.label_mask = label_mask\n",
    "        \n",
    "    def __iter__(self, shuffle=False):\n",
    "        batch_token_ids, batch_segment_ids, batch_labels, batch_label_mask = [], [], [], []\n",
    "        for is_end, item in self.get_sample(shuffle):\n",
    "            if len(item) == 4:\n",
    "                _, q, r, l = item\n",
    "                token_ids, segment_ids = tokenizer.encode(q,r, maxlen=maxlen)\n",
    "            else:\n",
    "                _, q, l = item\n",
    "                token_ids, segment_ids = tokenizer.encode(q, maxlen=maxlen)\n",
    "            \n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "            batch_labels.append([l])\n",
    "            batch_label_mask.append(self.label_mask)\n",
    "            \n",
    "            if is_end or self.batch_size == len(batch_token_ids):\n",
    "                batch_token_ids = pad_sequences(batch_token_ids)\n",
    "                batch_segment_ids = pad_sequences(batch_segment_ids)\n",
    "                batch_label_mask = pad_sequences(batch_label_mask)\n",
    "                batch_labels = pad_sequences(batch_labels)\n",
    "                \n",
    "                yield [batch_token_ids, batch_segment_ids, batch_labels, batch_label_mask], None\n",
    "                batch_token_ids, batch_segment_ids, batch_labels, batch_label_mask = [], [], [], []\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 101,  677, 6440, 3198, 2110, 4495, 2797, 3322, 1510,  702,  679,\n",
       "           977,  117, 5439, 2360,  671, 2584,  722,  678, 2828, 2797, 3322,\n",
       "          3035,  749,  117, 2157, 7270, 2897, 1355, 4873, 6375, 5439, 2360,\n",
       "          6608,  117, 1920, 2157, 2582,  720, 4692, 2521, 6821, 4905,  752,\n",
       "           136,  102],\n",
       "         [ 101, 1555, 6617, 4384, 4413, 5500,  819, 3300, 7361, 1062, 1385,\n",
       "          1068,  754, 2454, 3309, 1726, 1908,  677, 3862, 6395, 1171,  769,\n",
       "          3211, 2792, 2190, 1062, 1385, 8109, 2399, 2399, 2428, 2845, 1440,\n",
       "          4638,  752, 1400, 2144, 3417, 7309, 6418, 1141, 4638, 1062, 1440,\n",
       "           102,    0],\n",
       "         [ 101, 6858, 6814,  704,  792, 1062, 1385,  743,  749,  753, 2797,\n",
       "          2791,  117, 7674,  802, 6963,  802,  749,  117, 4385, 1762, 1297,\n",
       "          2157,  679, 2682, 1297,  749,  511, 2582,  720, 1905, 4415,  136,\n",
       "           102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 8271, 2399, 1343,  915, 5384, 3172, 4692,  686, 4518, 3344,\n",
       "          2533, 5709, 1914, 2208, 7178,  136,  102,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 1178, 7557, 1143, 4638,  702, 2595, 7484, 3173,  117, 7440,\n",
       "          3209, 4633, 1921, 4344, 2137, 1169, 4276, 3173, 1501, 7674, 1355,\n",
       "           102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 1086, 3613, 6395, 3209,  749,  100, 3187, 3127, 3221, 1914,\n",
       "           720, 2163, 2174,  100,  100,  100, 6847, 1921, 4638,  704, 1744,\n",
       "           728,  729, 4413, 7339,  106,  102,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101,  676, 1093, 4688, 8945, 8860,  118, 1059, 4413, 7674,  702,\n",
       "          2972, 1139,  131,  757, 5468, 5381,  116, 1277, 1779, 7216,  116,\n",
       "          1093,  772, 1501, 4638, 4510, 1555, 2398, 1378,  102,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 7028,  976, 8549, 3173, 5739, 7413,  136, 1071, 2141, 7028,\n",
       "           976, 2190, 3274, 7434, 3341, 6432, 1398, 3416, 7028, 6206,  102,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 1963,  862, 1762, 1555,  689, 3833, 1220,  704,  679, 1358,\n",
       "           782, 3619, 7745,  136,  102,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 8467, 4276, 5273, 3517, 3457, 3297, 3946, 3382, 4638, 1724,\n",
       "           702,  703, 7781,  117, 2034, 6443, 6963, 3221,  671, 4495, 4638,\n",
       "          4886, 3698,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 1119,  756, 4777, 1355, 4638, 1744,  772,  697, 6762, 4510,\n",
       "          1220, 6756, 2582,  720, 3416,  117, 3300,  784,  720, 2661, 1599,\n",
       "           136,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 2791, 1765,  772, 4925, 6826, 6826, 3187, 3791, 1139, 1378,\n",
       "           136, 1925, 6121, 4777, 4955, 2229, 2229, 7270, 2528, 2566, 6821,\n",
       "          3416, 6432,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 2769, 1724, 1283,  671,  702, 3299,  117, 5439, 2038,  671,\n",
       "          1283,  758,  671,  702, 3299,  117, 2100, 3621, 1061,  674,  684,\n",
       "          3300,  697, 2207, 2111,  117, 3221, 1044,  743, 2791, 6820, 3221,\n",
       "          1044,  743, 6756,  136,  102,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101,  100,  772, 1765, 1215, 2245,  100, 3563, 2466,  711,  100,\n",
       "           691, 5806, 1169, 6863,  100, 6843, 1158, 3173, 2658, 2845,  102,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 1059, 1744, 7674,  702, 1925, 1765, 6084, 1394, 2398, 1378,\n",
       "          1762, 3772, 5862, 1765,  102,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0],\n",
       "         [ 101, 3125,  752,  131, 1155,  712,  818, 2456, 4343, 1767,  102,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0]]),\n",
       "  array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]]),\n",
       "  array([[10],\n",
       "         [ 7],\n",
       "         [ 3],\n",
       "         [14],\n",
       "         [ 2],\n",
       "         [ 4],\n",
       "         [ 2],\n",
       "         [ 0],\n",
       "         [ 4],\n",
       "         [13],\n",
       "         [ 2],\n",
       "         [ 3],\n",
       "         [ 8],\n",
       "         [ 7],\n",
       "         [ 7],\n",
       "         [ 9]]),\n",
       "  array([[1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0],\n",
       "         [1, 0, 0]])],\n",
       " None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 0.8\n",
    "tnews_mask = [1,0,0]\n",
    "ocnli_mask = [0,1,0]\n",
    "ocemotion_mask = [0,0,1]\n",
    "\n",
    "def split_train_valid(data, split):\n",
    "    n = int(len(data)*split)\n",
    "    train_data = data[:n]\n",
    "    valid_data = data[n:]\n",
    "    return train_data, valid_data\n",
    "\n",
    "\n",
    "tnews_train_data, tnews_valid_data = split_train_valid(tnews_train, split)\n",
    "ocnli_train_data, ocnli_valid_data = split_train_valid(ocnli_train, split)\n",
    "ocemotion_train_data, ocemotion_valid_data = split_train_valid(ocemotion_train, split)\n",
    "\n",
    "tnews_train_generator = batch_data_generator(data=tnews_train, batch_size=batch_size, label_mask=tnews_mask)\n",
    "tnews_valid_generator = batch_data_generator(data=tnews_valid_data, batch_size=batch_size, label_mask=tnews_mask)\n",
    "tnews_test_generator = batch_data_generator(data=tnews_test, batch_size=batch_size, label_mask=tnews_mask)\n",
    "\n",
    "ocnli_train_generator = batch_data_generator(data=ocnli_train_data, batch_size=batch_size, label_mask=ocnli_mask)\n",
    "ocnli_valid_generator = batch_data_generator(data=ocnli_valid_data, batch_size=batch_size, label_mask=ocnli_mask)\n",
    "ocnli_test_generator = batch_data_generator(data=ocnli_test, batch_size=batch_size, label_mask=ocnli_mask)\n",
    "\n",
    "\n",
    "ocemotion_train_generator = batch_data_generator(data=ocemotion_train_data, batch_size=batch_size, label_mask=ocemotion_mask)\n",
    "ocemotion_valid_generator = batch_data_generator(data=ocemotion_valid_data, batch_size=batch_size, label_mask=ocemotion_mask)\n",
    "ocemotion_test_generator = batch_data_generator(data=ocemotion_test, batch_size=batch_size, label_mask=ocemotion_mask)\n",
    "\n",
    "tnews_train_generator.take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchLoss(Loss):\n",
    "    \"\"\"计算三种cls 的loss，然后通过 loss mask 过滤掉非当前任务的loss\n",
    "    这里也可以利用loss mask对不同task 的loss 加权\n",
    "    \"\"\"\n",
    "    def compute_loss(self, inputs, mask=None):\n",
    "        tnew_pred, ocnli_pred, ocemotion_pred, y_true, type_input = inputs\n",
    "        \n",
    "        train_loss = tf.case([(tf.equal(tf.argmax(type_input[0]), 0), lambda: K.sparse_categorical_crossentropy(y_true, tnews_cls)),\n",
    "                       (tf.equal(tf.argmax(type_input[0]), 1), lambda: K.sparse_categorical_crossentropy(y_true,ocnli_cls)),\n",
    "                        (tf.equal(tf.argmax(type_input[0]), 2), lambda: K.sparse_categorical_crossentropy(y_true, ocemotion_cls))\n",
    "                       ], exclusive=True)\n",
    "        return K.mean(train_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = build_transformer_model(checkpoint_path=checkpoint_path, config_path=config_path, model='nezha', with_pool=True)\n",
    "output = Dropout(0.1)(bert.output)\n",
    "\n",
    "tnews_cls = Dense(units=len(tnews_labels), activation='softmax')(output)\n",
    "ocnli_cls = Dense(units=len(ocnli_labels), activation='softmax')(output)\n",
    "ocemotion_cls = Dense(units=len(ocemotion_labels), activation='softmax')(output)\n",
    "\n",
    "y_input = Input(shape=(None, ))\n",
    "type_input = Input(shape=(None,))\n",
    "\n",
    "train_output = SwitchLoss(0)([tnews_cls, ocnli_cls, ocemotion_cls, y_input, type_input])\n",
    "\n",
    "train_model = Model(bert.inputs + [y_input, type_input], train_output)\n",
    "\n",
    "tnews_model = Model(bert.inputs, tnews_cls)\n",
    "ocnli_model = Model(bert.inputs, ocnli_cls)\n",
    "ocemotion_model = Model(bert.inputs, ocemotion_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Relative-Position-Embedding (Re (None, None, 64)     8256        Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n",
      "                                                                 Transformer-4-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n",
      "                                                                 Transformer-5-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n",
      "                                                                 Transformer-6-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n",
      "                                                                 Transformer-7-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n",
      "                                                                 Transformer-8-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n",
      "                                                                 Transformer-9-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n",
      "                                                                 Transformer-10-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Relative-Position-Embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n",
      "                                                                 Transformer-11-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Pooler (Lambda)                 (None, 768)          0           Transformer-11-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Pooler-Dense (Dense)            (None, 768)          590592      Pooler[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 768)          0           Pooler-Dense[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_148 (Dense)               (None, 15)           11535       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_149 (Dense)               (None, 3)            2307        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 7)            5383        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "switch_loss_2 (SwitchLoss)      (None, 15)           0           dense_148[0][0]                  \n",
      "                                                                 dense_149[0][0]                  \n",
      "                                                                 dense_150[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 101,901,913\n",
      "Trainable params: 101,893,657\n",
      "Non-trainable params: 8,256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mingming.xu/anaconda3/envs/keras/lib/python3.8/site-packages/keras/engine/training_utils.py:816: UserWarning: Output switch_loss_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to switch_loss_2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grad_accum_steps = 3\n",
    "Opt = extend_with_weight_decay(Adam)\n",
    "Opt = extend_with_gradient_accumulation(Opt)\n",
    "exclude_from_weight_decay = ['Norm', 'bias']\n",
    "Opt = extend_with_piecewise_linear_lr(Opt)\n",
    "para = {\n",
    "    'learning_rate': 2e-5,\n",
    "    'weight_decay_rate': 0.01,\n",
    "    'exclude_from_weight_decay': exclude_from_weight_decay,\n",
    "    'grad_accum_steps': grad_accum_steps,\n",
    "    'lr_schedule': {int(len(train_generator) * 0.1 * epochs / grad_accum_steps): 1, int(len(train_generator) * epochs / grad_accum_steps): 0},\n",
    "}\n",
    "\n",
    "opt = Opt(**para)\n",
    "\n",
    "train_model.compile(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report, f1_score\n",
    "\n",
    "\n",
    "def get_f1(l_t, l_p):\n",
    "    marco_f1_score = f1_score(l_t, l_p, average='macro')\n",
    "    return marco_f1_score\n",
    "\n",
    "def print_result(l_t, l_p):\n",
    "    marco_f1_score = f1_score(l_t, l_p, average='macro')\n",
    "    print(marco_f1_score)\n",
    "    print(f\"{'confusion_matrix':*^80}\")\n",
    "    print(confusion_matrix(l_t, l_p, ))\n",
    "    print(f\"{'classification_report':*^80}\")\n",
    "    print(classification_report(l_t, l_p, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(model, data):\n",
    "    preds, trues = [],[]\n",
    "    for (t, s, y, _),_ in tqdm(data):\n",
    "        pred = model.predict([t,s]).argmax(-1)\n",
    "        preds.extend(pred.tolist())\n",
    "        trues.extend(y.tolist())\n",
    "    return trues, preds\n",
    "\n",
    "    \n",
    "def evaluate():\n",
    "    tnews_trues, tnews_preds = get_predict(tnews_model, tnews_valid_generator)\n",
    "    ocnli_trues, ocnli_preds = get_predict(ocnli_model, ocnli_valid_generator)\n",
    "    ocemotion_trues, ocemotion_preds = get_predict(ocemotion_model, ocemotion_valid_generator)\n",
    "    \n",
    "    tnews_f1 = get_f1(tnews_trues, tnews_preds)\n",
    "    ocnli_f1 = get_f1(ocnli_trues, ocnli_preds)\n",
    "    ocemotion_f1 = get_f1(ocemotion_trues, ocemotion_preds)\n",
    "    \n",
    "    print_result(tnews_trues, tnews_preds)\n",
    "    print_result(ocnli_trues, ocnli_preds)\n",
    "    print_result(ocemotion_trues, ocemotion_preds)\n",
    "\n",
    "    score = (tnews_f1 + ocnli_f1 + ocemotion_f1) / 3\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(keras.callbacks.Callback):\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.best_f1 = 0.\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        avg_f1 = evaluate()\n",
    "        if self.best_f1 < avg_f1:\n",
    "            self.best_f1 = avg_f1\n",
    "            self.model.save_weights(self.save_path)\n",
    "        \n",
    "        print('epoch: {} f1 is:{},  best f1 is:{}'.format(epoch +1, avg_f1, self.best_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:15<00:00, 50.83it/s]\n",
      "100%|██████████| 668/668 [00:18<00:00, 35.33it/s]\n",
      "100%|██████████| 447/447 [00:27<00:00, 15.99it/s]\n",
      "/home/mingming.xu/anaconda3/envs/keras/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027631714609753586\n",
      "********************************confusion_matrix********************************\n",
      "[[   0    0    0    1    0    0    0    0    0  840    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0   56    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    1    0    0    0    0    0 1393    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0  490    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0  974    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0 1171    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0  907    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    5    0    0    0    0    0 1195    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0  985    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0  268    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0  817    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0  622    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0 1166    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    0    0  945    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    1    0    0    0    0    0  835    0    0    0    0\n",
      "     0]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       841\n",
      "           1       0.00      0.00      0.00        56\n",
      "           2       0.00      0.00      0.00      1394\n",
      "           3       0.00      0.00      0.00       490\n",
      "           4       0.00      0.00      0.00       974\n",
      "           5       0.00      0.00      0.00      1171\n",
      "           6       0.00      0.00      0.00       907\n",
      "           7       0.00      0.00      0.00      1200\n",
      "           8       0.00      0.00      0.00       985\n",
      "           9       0.02      1.00      0.04       268\n",
      "          10       0.00      0.00      0.00       817\n",
      "          11       0.00      0.00      0.00       622\n",
      "          12       0.00      0.00      0.00      1166\n",
      "          13       0.00      0.00      0.00       945\n",
      "          14       0.00      0.00      0.00       836\n",
      "\n",
      "    accuracy                           0.02     12672\n",
      "   macro avg       0.00      0.07      0.00     12672\n",
      "weighted avg       0.00      0.02      0.00     12672\n",
      "\n",
      "0.17900735638589535\n",
      "********************************confusion_matrix********************************\n",
      "[[3697   53    0]\n",
      " [3416   36    2]\n",
      " [3442   32    0]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.99      0.52      3750\n",
      "           1       0.30      0.01      0.02      3454\n",
      "           2       0.00      0.00      0.00      3474\n",
      "\n",
      "    accuracy                           0.35     10678\n",
      "   macro avg       0.22      0.33      0.18     10678\n",
      "weighted avg       0.22      0.35      0.19     10678\n",
      "\n",
      "0.009952941809709123\n",
      "********************************confusion_matrix********************************\n",
      "[[  26 1743   12    0    0    0    0]\n",
      " [   3  118    0    0    0    0    0]\n",
      " [  16  810    4    0    0    0    0]\n",
      " [  22  875    2    0    0    0    0]\n",
      " [   2  172    0    0    0    0    0]\n",
      " [  19  777    2    0    0    0    0]\n",
      " [  50 2475   11    0    0    0    0]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.01      0.03      1781\n",
      "           1       0.02      0.98      0.03       121\n",
      "           2       0.13      0.00      0.01       830\n",
      "           3       0.00      0.00      0.00       899\n",
      "           4       0.00      0.00      0.00       174\n",
      "           5       0.00      0.00      0.00       798\n",
      "           6       0.00      0.00      0.00      2536\n",
      "\n",
      "    accuracy                           0.02      7139\n",
      "   macro avg       0.05      0.14      0.01      7139\n",
      "weighted avg       0.06      0.02      0.01      7139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06390782321885995"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    def __iter__(self, shuffle=False):\n",
    "        for is_end, item in self.get_sample(shuffle):\n",
    "            yield item\n",
    "\n",
    "train_batch_data = list(tnews_train_generator.__iter__(shuffle=True)) + list(ocnli_train_generator.__iter__(shuffle=True))\n",
    "train_batch_data += list(ocemotion_train_generator.__iter__(shuffle=True))\n",
    "train_generator = data_generator(data=train_batch_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mingming.xu/anaconda3/envs/keras/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8415/8415 [==============================] - 1262s 150ms/step - loss: 0.2482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:15<00:00, 50.10it/s]\n",
      "100%|██████████| 668/668 [00:19<00:00, 34.67it/s]\n",
      "100%|██████████| 447/447 [00:29<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9692006472762918\n",
      "********************************confusion_matrix********************************\n",
      "[[ 812    0   11    0    2    4    4    1    1    0    2    1    1    2\n",
      "     0]\n",
      " [   0   56    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   1    0 1349    0    0    4    0   29    1    0    0    1    5    2\n",
      "     2]\n",
      " [   0    0    1  471    1    1    0   10    2    0    0    2    0    1\n",
      "     1]\n",
      " [   3    0    0    2  952    6    1    2    0    0    0    0    3    4\n",
      "     1]\n",
      " [   2    0    1    1    3 1130    4    1    0    0    1    0    3   25\n",
      "     0]\n",
      " [   1    0    3    0    2    2  851    0    0    0    1    0   38    8\n",
      "     1]\n",
      " [   0    4   29    0    0    0    1 1154    0    0    1    8    3    0\n",
      "     0]\n",
      " [   0    0   30    2    1    1    2    2  938    1    1    0    2    4\n",
      "     1]\n",
      " [   0    0    0    0    0    4    0    0    0  263    0    0    0    1\n",
      "     0]\n",
      " [   1    0    1    1    1    1    0    1    0    1  800    3    0    6\n",
      "     1]\n",
      " [   0    0    2    1    0    0    0    5    0    0    0  612    0    2\n",
      "     0]\n",
      " [   1    0    2    0    0    3   25    5    3    0    0    1 1122    1\n",
      "     3]\n",
      " [   0    0    0    0    2    1    0    2    0    0    1    2    1  935\n",
      "     1]\n",
      " [   0    0    3    4    0    0    3    2    2    0    0    2    5    5\n",
      "   810]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       841\n",
      "           1       0.93      1.00      0.97        56\n",
      "           2       0.94      0.97      0.95      1394\n",
      "           3       0.98      0.96      0.97       490\n",
      "           4       0.99      0.98      0.98       974\n",
      "           5       0.98      0.96      0.97      1171\n",
      "           6       0.96      0.94      0.95       907\n",
      "           7       0.95      0.96      0.96      1200\n",
      "           8       0.99      0.95      0.97       985\n",
      "           9       0.99      0.98      0.99       268\n",
      "          10       0.99      0.98      0.99       817\n",
      "          11       0.97      0.98      0.98       622\n",
      "          12       0.95      0.96      0.96      1166\n",
      "          13       0.94      0.99      0.96       945\n",
      "          14       0.99      0.97      0.98       836\n",
      "\n",
      "    accuracy                           0.97     12672\n",
      "   macro avg       0.97      0.97      0.97     12672\n",
      "weighted avg       0.97      0.97      0.97     12672\n",
      "\n",
      "0.7257649365069855\n",
      "********************************confusion_matrix********************************\n",
      "[[2820  447  483]\n",
      " [ 736 2531  187]\n",
      " [ 853  248 2373]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69      3750\n",
      "           1       0.78      0.73      0.76      3454\n",
      "           2       0.78      0.68      0.73      3474\n",
      "\n",
      "    accuracy                           0.72     10678\n",
      "   macro avg       0.73      0.72      0.73     10678\n",
      "weighted avg       0.73      0.72      0.72     10678\n",
      "\n",
      "0.48338975007199914\n",
      "********************************confusion_matrix********************************\n",
      "[[1192    8   48  106   23  145  259]\n",
      " [  15   48    3    9    5    7   34]\n",
      " [  85    9  234  127   10   31  334]\n",
      " [  81    5   89  406   12   44  262]\n",
      " [  33    0   12   20   42   15   52]\n",
      " [ 199    5   19   30    7  398  140]\n",
      " [ 207   12  125  168   21  168 1835]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1781\n",
      "           1       0.55      0.40      0.46       121\n",
      "           2       0.44      0.28      0.34       830\n",
      "           3       0.47      0.45      0.46       899\n",
      "           4       0.35      0.24      0.29       174\n",
      "           5       0.49      0.50      0.50       798\n",
      "           6       0.63      0.72      0.67      2536\n",
      "\n",
      "    accuracy                           0.58      7139\n",
      "   macro avg       0.51      0.47      0.48      7139\n",
      "weighted avg       0.57      0.58      0.57      7139\n",
      "\n",
      "epoch: 1 f1 is:0.7261184446184256,  best f1 is:0.7261184446184256\n",
      "Epoch 2/5\n",
      "8415/8415 [==============================] - 1269s 151ms/step - loss: 0.1592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:15<00:00, 50.81it/s]\n",
      "100%|██████████| 668/668 [00:19<00:00, 34.44it/s]\n",
      "100%|██████████| 447/447 [00:29<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9750340960011027\n",
      "********************************confusion_matrix********************************\n",
      "[[ 819    0    6    0    5    2    4    1    0    0    2    0    1    1\n",
      "     0]\n",
      " [   0   54    0    0    0    0    0    2    0    0    0    0    0    0\n",
      "     0]\n",
      " [   6    0 1357    1    1    2    0    9    9    0    1    1    7    0\n",
      "     0]\n",
      " [   0    0    2  477    0    1    0    4    2    0    0    2    0    0\n",
      "     2]\n",
      " [   0    1    0    0  954    7    2    2    2    0    0    0    3    3\n",
      "     0]\n",
      " [   1    0    3    0    1 1152    2    0    1    1    0    1    5    4\n",
      "     0]\n",
      " [   0    0    1    0    1    1  864    1    1    0    0    0   35    2\n",
      "     1]\n",
      " [   0    1   17    4    1    1    0 1157    0    0    0    8   11    0\n",
      "     0]\n",
      " [   0    0    6    1    1    1    0    3  966    0    0    0    0    4\n",
      "     3]\n",
      " [   0    0    0    0    0    0    0    0    0  266    0    0    1    1\n",
      "     0]\n",
      " [   2    0    4    1    1    0    0    1    0    2  797    4    1    3\n",
      "     1]\n",
      " [   0    0    0    0    0    0    0    0    1    1    0  619    0    0\n",
      "     1]\n",
      " [   0    0    1    0    0    2   20    1    1    0    0    1 1138    0\n",
      "     2]\n",
      " [   0    1    0    0    1    7    2    1    1    1    1    3    1  925\n",
      "     1]\n",
      " [   0    0    2    1    1    2    2    1    5    0    0    3    8    1\n",
      "   810]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       841\n",
      "           1       0.95      0.96      0.96        56\n",
      "           2       0.97      0.97      0.97      1394\n",
      "           3       0.98      0.97      0.98       490\n",
      "           4       0.99      0.98      0.98       974\n",
      "           5       0.98      0.98      0.98      1171\n",
      "           6       0.96      0.95      0.96       907\n",
      "           7       0.98      0.96      0.97      1200\n",
      "           8       0.98      0.98      0.98       985\n",
      "           9       0.98      0.99      0.99       268\n",
      "          10       1.00      0.98      0.99       817\n",
      "          11       0.96      1.00      0.98       622\n",
      "          12       0.94      0.98      0.96      1166\n",
      "          13       0.98      0.98      0.98       945\n",
      "          14       0.99      0.97      0.98       836\n",
      "\n",
      "    accuracy                           0.97     12672\n",
      "   macro avg       0.97      0.98      0.98     12672\n",
      "weighted avg       0.98      0.97      0.98     12672\n",
      "\n",
      "0.7187258907772008\n",
      "********************************confusion_matrix********************************\n",
      "[[2878  472  400]\n",
      " [ 710 2541  203]\n",
      " [ 984  254 2236]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.77      0.69      3750\n",
      "           1       0.78      0.74      0.76      3454\n",
      "           2       0.79      0.64      0.71      3474\n",
      "\n",
      "    accuracy                           0.72     10678\n",
      "   macro avg       0.73      0.72      0.72     10678\n",
      "weighted avg       0.73      0.72      0.72     10678\n",
      "\n",
      "0.4596851093064283\n",
      "********************************confusion_matrix********************************\n",
      "[[1257    9   47   25   27  163  253]\n",
      " [  15   41    4    4    7    6   44]\n",
      " [  94   12  220   66   47   37  354]\n",
      " [ 130    5   93  289   35   33  314]\n",
      " [  42    2   11    5   49   20   45]\n",
      " [ 200    7    7   12   12  406  154]\n",
      " [ 266   17  130   85   40  141 1857]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.66      1781\n",
      "           1       0.44      0.34      0.38       121\n",
      "           2       0.43      0.27      0.33       830\n",
      "           3       0.59      0.32      0.42       899\n",
      "           4       0.23      0.28      0.25       174\n",
      "           5       0.50      0.51      0.51       798\n",
      "           6       0.61      0.73      0.67      2536\n",
      "\n",
      "    accuracy                           0.58      7139\n",
      "   macro avg       0.49      0.45      0.46      7139\n",
      "weighted avg       0.57      0.58      0.56      7139\n",
      "\n",
      "epoch: 2 f1 is:0.7178150320282439,  best f1 is:0.7261184446184256\n",
      "Epoch 3/5\n",
      "8415/8415 [==============================] - 1270s 151ms/step - loss: 0.1280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:15<00:00, 50.07it/s]\n",
      "100%|██████████| 668/668 [00:19<00:00, 34.59it/s]\n",
      "100%|██████████| 447/447 [00:29<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787213268832121\n",
      "********************************confusion_matrix********************************\n",
      "[[ 830    0    4    0    2    2    1    1    0    0    0    0    1    0\n",
      "     0]\n",
      " [   0   56    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   5    0 1362    1    1    4    1   13    1    0    3    1    0    1\n",
      "     1]\n",
      " [   0    1    2  479    0    1    0    2    2    0    0    2    0    0\n",
      "     1]\n",
      " [   5    1    1    0  960    1    0    0    0    0    0    0    1    3\n",
      "     2]\n",
      " [   1    0    0    1    6 1154    2    0    0    2    0    1    0    4\n",
      "     0]\n",
      " [   2    0    2    0    1    1  852    2    0    0    1    0   39    4\n",
      "     3]\n",
      " [   0    5    7    2    1    0    0 1173    1    0    1    8    1    0\n",
      "     1]\n",
      " [   1    0    4    1    0    0    1    0  970    0    0    0    0    2\n",
      "     6]\n",
      " [   0    0    0    0    0    0    0    0    0  266    0    2    0    0\n",
      "     0]\n",
      " [   0    0    1    0    1    0    0    0    0    0  812    2    0    1\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0  621    0    0\n",
      "     0]\n",
      " [   0    0    3    0    0    5    9    3    2    0    1    0 1136    0\n",
      "     7]\n",
      " [   0    0    0    0    3    3    0    1    1    1    5    3    0  923\n",
      "     5]\n",
      " [   0    0    0    1    0    0    0    0    3    0    0    0    3    0\n",
      "   829]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       841\n",
      "           1       0.89      1.00      0.94        56\n",
      "           2       0.98      0.98      0.98      1394\n",
      "           3       0.99      0.98      0.98       490\n",
      "           4       0.98      0.99      0.99       974\n",
      "           5       0.99      0.99      0.99      1171\n",
      "           6       0.98      0.94      0.96       907\n",
      "           7       0.98      0.98      0.98      1200\n",
      "           8       0.99      0.98      0.99       985\n",
      "           9       0.99      0.99      0.99       268\n",
      "          10       0.99      0.99      0.99       817\n",
      "          11       0.97      1.00      0.98       622\n",
      "          12       0.96      0.97      0.97      1166\n",
      "          13       0.98      0.98      0.98       945\n",
      "          14       0.97      0.99      0.98       836\n",
      "\n",
      "    accuracy                           0.98     12672\n",
      "   macro avg       0.98      0.98      0.98     12672\n",
      "weighted avg       0.98      0.98      0.98     12672\n",
      "\n",
      "0.7257690151962759\n",
      "********************************confusion_matrix********************************\n",
      "[[2664  561  525]\n",
      " [ 566 2644  244]\n",
      " [ 755  292 2427]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      3750\n",
      "           1       0.76      0.77      0.76      3454\n",
      "           2       0.76      0.70      0.73      3474\n",
      "\n",
      "    accuracy                           0.72     10678\n",
      "   macro avg       0.73      0.72      0.73     10678\n",
      "weighted avg       0.73      0.72      0.72     10678\n",
      "\n",
      "0.48100209283286055\n",
      "********************************confusion_matrix********************************\n",
      "[[1200    8   88   90   36  148  211]\n",
      " [  14   48    5    6    3    6   39]\n",
      " [  79   11  340  123   23   25  229]\n",
      " [  87    9  166  397   17   30  193]\n",
      " [  27    2   21   22   52   19   31]\n",
      " [ 180    7   22   44   12  392  141]\n",
      " [ 205   46  244  202   36  114 1689]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67      1781\n",
      "           1       0.37      0.40      0.38       121\n",
      "           2       0.38      0.41      0.40       830\n",
      "           3       0.45      0.44      0.45       899\n",
      "           4       0.29      0.30      0.29       174\n",
      "           5       0.53      0.49      0.51       798\n",
      "           6       0.67      0.67      0.67      2536\n",
      "\n",
      "    accuracy                           0.58      7139\n",
      "   macro avg       0.48      0.48      0.48      7139\n",
      "weighted avg       0.58      0.58      0.58      7139\n",
      "\n",
      "epoch: 3 f1 is:0.7284974783041163,  best f1 is:0.7284974783041163\n",
      "Epoch 4/5\n",
      "8415/8415 [==============================] - 1269s 151ms/step - loss: 0.1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:15<00:00, 49.95it/s]\n",
      "100%|██████████| 668/668 [00:19<00:00, 34.57it/s]\n",
      "100%|██████████| 447/447 [00:29<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983222848493567\n",
      "********************************confusion_matrix********************************\n",
      "[[ 822    0    7    0    5    2    1    2    0    0    1    0    0    1\n",
      "     0]\n",
      " [   0   56    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2    0 1368    1    2    5    2   11    1    0    0    0    0    2\n",
      "     0]\n",
      " [   0    0    0  476    0    0    0    4    4    0    0    1    0    0\n",
      "     5]\n",
      " [   0    1    0    0  965    4    0    0    1    0    0    0    0    3\n",
      "     0]\n",
      " [   3    0    1    1    0 1153    2    0    0    1    0    0    2    8\n",
      "     0]\n",
      " [   3    0    0    0    0    1  881    1    0    0    0    0   18    2\n",
      "     1]\n",
      " [   0    1    7    0    2    0    1 1185    0    0    1    3    0    0\n",
      "     0]\n",
      " [   0    0    6    1    0    0    0    0  972    0    0    0    0    3\n",
      "     3]\n",
      " [   0    0    0    0    0    0    0    0    0  267    0    1    0    0\n",
      "     0]\n",
      " [   2    0    3    0    1    0    1    0    2    0  803    3    0    1\n",
      "     1]\n",
      " [   0    0    0    0    0    0    0    1    1    0    0  617    0    3\n",
      "     0]\n",
      " [   0    0    3    0    0    1   23    2    3    0    2    0 1128    1\n",
      "     3]\n",
      " [   0    0    0    0    3    6    2    1    0    0    2    1    1  927\n",
      "     2]\n",
      " [   0    0    0    1    0    0    0    0    4    0    0    1    2    0\n",
      "   828]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       841\n",
      "           1       0.97      1.00      0.98        56\n",
      "           2       0.98      0.98      0.98      1394\n",
      "           3       0.99      0.97      0.98       490\n",
      "           4       0.99      0.99      0.99       974\n",
      "           5       0.98      0.98      0.98      1171\n",
      "           6       0.96      0.97      0.97       907\n",
      "           7       0.98      0.99      0.98      1200\n",
      "           8       0.98      0.99      0.99       985\n",
      "           9       1.00      1.00      1.00       268\n",
      "          10       0.99      0.98      0.99       817\n",
      "          11       0.98      0.99      0.99       622\n",
      "          12       0.98      0.97      0.97      1166\n",
      "          13       0.97      0.98      0.98       945\n",
      "          14       0.98      0.99      0.99       836\n",
      "\n",
      "    accuracy                           0.98     12672\n",
      "   macro avg       0.98      0.98      0.98     12672\n",
      "weighted avg       0.98      0.98      0.98     12672\n",
      "\n",
      "0.717892755398068\n",
      "********************************confusion_matrix********************************\n",
      "[[2742  553  455]\n",
      " [ 627 2593  234]\n",
      " [ 921  243 2310]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68      3750\n",
      "           1       0.77      0.75      0.76      3454\n",
      "           2       0.77      0.66      0.71      3474\n",
      "\n",
      "    accuracy                           0.72     10678\n",
      "   macro avg       0.72      0.72      0.72     10678\n",
      "weighted avg       0.72      0.72      0.72     10678\n",
      "\n",
      "0.4772520353774919\n",
      "********************************confusion_matrix********************************\n",
      "[[1387    7   28   38   12  142  167]\n",
      " [  19   44    1    5    2    6   44]\n",
      " [ 143    7  256   78   20   33  293]\n",
      " [ 178    8   93  328   16   43  233]\n",
      " [  54    0   11    6   41   18   44]\n",
      " [ 243    6   19   14    4  402  110]\n",
      " [ 361   25  144   97   19  168 1722]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.67      1781\n",
      "           1       0.45      0.36      0.40       121\n",
      "           2       0.46      0.31      0.37       830\n",
      "           3       0.58      0.36      0.45       899\n",
      "           4       0.36      0.24      0.28       174\n",
      "           5       0.50      0.50      0.50       798\n",
      "           6       0.66      0.68      0.67      2536\n",
      "\n",
      "    accuracy                           0.59      7139\n",
      "   macro avg       0.51      0.46      0.48      7139\n",
      "weighted avg       0.58      0.59      0.57      7139\n",
      "\n",
      "epoch: 4 f1 is:0.7261225464230424,  best f1 is:0.7284974783041163\n",
      "Epoch 5/5\n",
      "8415/8415 [==============================] - 1270s 151ms/step - loss: 0.0963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:15<00:00, 49.99it/s]\n",
      "100%|██████████| 668/668 [00:19<00:00, 34.53it/s]\n",
      "100%|██████████| 447/447 [00:29<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9807532205109957\n",
      "********************************confusion_matrix********************************\n",
      "[[ 826    0    6    0    3    3    1    1    0    0    1    0    0    0\n",
      "     0]\n",
      " [   0   56    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   4    0 1371    0    2    2    0    7    3    0    1    1    1    1\n",
      "     1]\n",
      " [   0    0    1  485    0    0    0    2    1    0    0    0    0    0\n",
      "     1]\n",
      " [   1    1    1    0  966    1    0    0    0    0    0    0    0    3\n",
      "     1]\n",
      " [   1    0    1    0    6 1155    2    0    0    0    2    0    0    4\n",
      "     0]\n",
      " [   1    0    3    0    2    1  865    1    0    0    2    1   27    3\n",
      "     1]\n",
      " [   0    3   16    8    2    0    0 1153    0    0    0   12    3    1\n",
      "     2]\n",
      " [   0    0    4    1    1    0    1    0  970    0    0    0    1    4\n",
      "     3]\n",
      " [   0    0    0    0    0    1    1    0    0  262    2    1    0    1\n",
      "     0]\n",
      " [   0    0    2    0    0    0    0    0    0    0  812    2    0    1\n",
      "     0]\n",
      " [   0    0    0    0    0    1    0    0    1    0    0  619    0    1\n",
      "     0]\n",
      " [   0    0    4    0    0    1   18    1    2    0    1    1 1130    0\n",
      "     8]\n",
      " [   0    0    0    0    4    3    0    1    0    0    0    2    0  931\n",
      "     4]\n",
      " [   0    0    1    2    0    1    0    0    3    0    0    0    0    0\n",
      "   829]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       841\n",
      "           1       0.93      1.00      0.97        56\n",
      "           2       0.97      0.98      0.98      1394\n",
      "           3       0.98      0.99      0.98       490\n",
      "           4       0.98      0.99      0.99       974\n",
      "           5       0.99      0.99      0.99      1171\n",
      "           6       0.97      0.95      0.96       907\n",
      "           7       0.99      0.96      0.97      1200\n",
      "           8       0.99      0.98      0.99       985\n",
      "           9       1.00      0.98      0.99       268\n",
      "          10       0.99      0.99      0.99       817\n",
      "          11       0.97      1.00      0.98       622\n",
      "          12       0.97      0.97      0.97      1166\n",
      "          13       0.98      0.99      0.98       945\n",
      "          14       0.98      0.99      0.98       836\n",
      "\n",
      "    accuracy                           0.98     12672\n",
      "   macro avg       0.98      0.98      0.98     12672\n",
      "weighted avg       0.98      0.98      0.98     12672\n",
      "\n",
      "0.7250612487372269\n",
      "********************************confusion_matrix********************************\n",
      "[[2841  433  476]\n",
      " [ 713 2511  230]\n",
      " [ 862  244 2368]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.70      3750\n",
      "           1       0.79      0.73      0.76      3454\n",
      "           2       0.77      0.68      0.72      3474\n",
      "\n",
      "    accuracy                           0.72     10678\n",
      "   macro avg       0.73      0.72      0.73     10678\n",
      "weighted avg       0.73      0.72      0.72     10678\n",
      "\n",
      "0.4487293241299445\n",
      "********************************confusion_matrix********************************\n",
      "[[1058    9   22  121   13  230  328]\n",
      " [   8   43    0    8    3    5   54]\n",
      " [  52    9  111  184   15   35  424]\n",
      " [  46   11   36  434   17   40  315]\n",
      " [  20    0    3   33   39   23   56]\n",
      " [ 122   10    5   45    4  411  201]\n",
      " [ 125   23   46  211   18  125 1988]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.59      0.66      1781\n",
      "           1       0.41      0.36      0.38       121\n",
      "           2       0.50      0.13      0.21       830\n",
      "           3       0.42      0.48      0.45       899\n",
      "           4       0.36      0.22      0.28       174\n",
      "           5       0.47      0.52      0.49       798\n",
      "           6       0.59      0.78      0.67      2536\n",
      "\n",
      "    accuracy                           0.57      7139\n",
      "   macro avg       0.50      0.44      0.45      7139\n",
      "weighted avg       0.57      0.57      0.55      7139\n",
      "\n",
      "epoch: 5 f1 is:0.718181264459389,  best f1 is:0.7284974783041163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f1d90cc2e20>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = 'best_model.weights'\n",
    "evaluator = Evaluator(save_path)\n",
    "\n",
    "train_model.fit_generator(train_generator.generator(),\n",
    "                         steps_per_epoch=len(train_generator),\n",
    "                         epochs=epochs,\n",
    "                          callbacks=[evaluator]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:14<00:00, 55.96it/s]\n",
      "100%|██████████| 668/668 [00:17<00:00, 39.13it/s]\n",
      "100%|██████████| 447/447 [00:26<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9566871717092731\n",
      "********************************confusion_matrix********************************\n",
      "[[ 814    0    6    1    7    2    1    1    4    0    1    0    2    2\n",
      "     0]\n",
      " [   0   55    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0]\n",
      " [   9    0 1321    2    1    4    2   37    6    0    2    1    4    2\n",
      "     3]\n",
      " [   0    0    1  475    1    0    0    8    1    0    0    2    0    0\n",
      "     2]\n",
      " [   0    1    4    1  949    6    1    1    2    0    2    1    1    4\n",
      "     1]\n",
      " [   3    0    7    1    3 1134    1    1    0    7    2    0    4    7\n",
      "     1]\n",
      " [   8    0    3    0    2    1  800    2    0    0    0    1   83    4\n",
      "     3]\n",
      " [   0    2   40    8    1    0    1 1123    2    1    0    8   12    1\n",
      "     1]\n",
      " [   1    0   20    3    2    4    3    3  923    2    0    0    3    5\n",
      "    16]\n",
      " [   0    0    0    0    0    2    0    0    0  262    1    2    0    1\n",
      "     0]\n",
      " [   0    0    2    2    2    1    2    4    0    2  795    2    3    1\n",
      "     1]\n",
      " [   0    0    2    0    0    0    0    5    1    0    0  610    2    1\n",
      "     1]\n",
      " [   1    0    2    1    0   11   16    2    2    1    0    1 1125    0\n",
      "     4]\n",
      " [   0    1    0    0    2   12    2    1    1    3    3    4    5  911\n",
      "     0]\n",
      " [   0    0    3    3    0    1    2    4    3    0    0    4   15    2\n",
      "   799]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       841\n",
      "           1       0.93      0.98      0.96        56\n",
      "           2       0.94      0.95      0.94      1394\n",
      "           3       0.96      0.97      0.96       490\n",
      "           4       0.98      0.97      0.98       974\n",
      "           5       0.96      0.97      0.97      1171\n",
      "           6       0.96      0.88      0.92       907\n",
      "           7       0.94      0.94      0.94      1200\n",
      "           8       0.98      0.94      0.96       985\n",
      "           9       0.94      0.98      0.96       268\n",
      "          10       0.99      0.97      0.98       817\n",
      "          11       0.96      0.98      0.97       622\n",
      "          12       0.89      0.96      0.93      1166\n",
      "          13       0.97      0.96      0.97       945\n",
      "          14       0.96      0.96      0.96       836\n",
      "\n",
      "    accuracy                           0.95     12672\n",
      "   macro avg       0.96      0.96      0.96     12672\n",
      "weighted avg       0.96      0.95      0.95     12672\n",
      "\n",
      "0.7303057411489192\n",
      "********************************confusion_matrix********************************\n",
      "[[2762  512  476]\n",
      " [ 613 2642  199]\n",
      " [ 794  302 2378]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.74      0.70      3750\n",
      "           1       0.76      0.76      0.76      3454\n",
      "           2       0.78      0.68      0.73      3474\n",
      "\n",
      "    accuracy                           0.73     10678\n",
      "   macro avg       0.74      0.73      0.73     10678\n",
      "weighted avg       0.73      0.73      0.73     10678\n",
      "\n",
      "0.4961666587028145\n",
      "********************************confusion_matrix********************************\n",
      "[[1299    6   65   84   12  166  149]\n",
      " [  14   44   10    6    5   12   30]\n",
      " [  90    5  351  119   14   34  217]\n",
      " [ 135    4  134  403    7   39  177]\n",
      " [  36    0   26   24   40   18   30]\n",
      " [ 208    4   29   30    4  439   84]\n",
      " [ 284    9  253  206   19  176 1589]]\n",
      "*****************************classification_report******************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.68      1781\n",
      "           1       0.61      0.36      0.46       121\n",
      "           2       0.40      0.42      0.41       830\n",
      "           3       0.46      0.45      0.46       899\n",
      "           4       0.40      0.23      0.29       174\n",
      "           5       0.50      0.55      0.52       798\n",
      "           6       0.70      0.63      0.66      2536\n",
      "\n",
      "    accuracy                           0.58      7139\n",
      "   macro avg       0.53      0.48      0.50      7139\n",
      "weighted avg       0.59      0.58      0.58      7139\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7277198571870023"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model.load_weights(model_save_path)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_to_file(result_path):\n",
    "    _, tnews_preds = get_predict(tnews_model, tnews_test_generator)\n",
    "    _, ocnli_preds = get_predict(ocnli_model, ocnli_test_generator)\n",
    "    _, ocemotion_preds = get_predict(ocemotion_model, ocemotion_test_generator)\n",
    "    \n",
    "    tnews_result, ocnli_result, ocemotion_result = [], [], []\n",
    "    \n",
    "    for (d, p) in zip(tnews_test, tnews_preds):\n",
    "        tnews_result.append({'id': d[0], 'label': tnews_id2label[p]})\n",
    "    \n",
    "    for (d, p) in zip(ocnli_test, ocnli_preds):\n",
    "        ocnli_result.append({'id': d[0], 'label': ocnli_id2label[p]})\n",
    "    \n",
    "    for (d, p) in zip(ocemotion_test, ocemotion_preds):\n",
    "        ocemotion_result.append({'id': d[0], 'label': ocemotion_id2label[p]})\n",
    "        \n",
    "    with open(os.path.join(result_path, 'tnews_predict.json'), 'w') as f:\n",
    "        for d in tnews_result:\n",
    "            f.write(json.dumps(d) + '\\n')\n",
    "    \n",
    "    with open(os.path.join(result_path, 'ocnli_predict.json'), 'w') as f:\n",
    "        for d in ocnli_result:\n",
    "            f.write(json.dumps(d) + '\\n')\n",
    "    \n",
    "    with open(os.path.join(result_path, 'ocemotion_predict.json'), 'w') as f:\n",
    "        for d in ocemotion_result:\n",
    "            f.write(json.dumps(d) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:01<00:00, 53.05it/s]\n",
      "100%|██████████| 94/94 [00:02<00:00, 35.43it/s]\n",
      "100%|██████████| 94/94 [00:05<00:00, 17.50it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_to_file('./result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
